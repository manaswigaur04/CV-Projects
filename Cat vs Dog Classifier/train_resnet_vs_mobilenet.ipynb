{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NBz2xNe1tryk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CvWJTqeMub9I"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "    saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "    [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# No augmentation for validation/test\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "    [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3CY4lBIrue0u"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder('data/train', transform=train_transforms)\n",
        "val_dataset = datasets.ImageFolder('data/val', transform=val_transforms)\n",
        "test_dataset = datasets.ImageFolder('data/test', transform=val_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw8U6Kq2uhSj",
        "outputId": "7c235ef2-ba34-4886-b68d-d44c06886c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 19999\n",
            "Validation samples: 2500\n",
            "Test samples: 2460\n"
          ]
        }
      ],
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f'Training samples: {len(train_dataset)}')\n",
        "print(f'Validation samples: {len(val_dataset)}')\n",
        "print(f'Test samples: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LjHNxKsuiyQ",
        "outputId": "38f9d849-2ff0-4745-c4af-06d6ce93cc07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Move to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1QXb_ji-vL7z"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model_name):\n",
        "    print(f\"\\n{'='*20} Training {model_name} {'='*20}\")\n",
        "\n",
        "    if model_name == 'ResNet18':\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        # Freeze all layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Replace final layer for binary classification\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, 2)\n",
        "        optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "    elif model_name == 'MobileNetV2':\n",
        "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "        # Freeze all layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Replace final layer for binary classification\n",
        "        # MobileNetV2 classifier is a Sequential block, last layer is Linear\n",
        "        num_features = model.classifier[1].in_features\n",
        "        model.classifier[1] = nn.Linear(num_features, 2)\n",
        "        optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_path = f'best_model_{model_name}.pth'\n",
        "\n",
        "    num_epochs = 10 # Keep same as original\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_running_loss / len(val_loader)\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f'Saved best model with val_acc: {val_acc:.2f}%')\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "    # Load best model for testing\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    model.eval()\n",
        "\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / test_total\n",
        "    print(f'{model_name} Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    # return test_accuracy, train_losses, val_losses, train_accs, val_accs\n",
        "    return test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Xblo3-vfsC",
        "outputId": "1d488372-20e1-45d5-e783-487b273208c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Training ResNet18 ====================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved best model with val_acc: 97.80%\n",
            "Epoch [1/10] Train Loss: 0.1640, Train Acc: 93.41% | Val Loss: 0.0612, Val Acc: 97.80%\n",
            "Saved best model with val_acc: 98.04%\n",
            "Epoch [2/10] Train Loss: 0.1142, Train Acc: 95.29% | Val Loss: 0.0531, Val Acc: 98.04%\n",
            "Saved best model with val_acc: 98.20%\n",
            "Epoch [3/10] Train Loss: 0.1111, Train Acc: 95.53% | Val Loss: 0.0518, Val Acc: 98.20%\n",
            "Epoch [4/10] Train Loss: 0.1121, Train Acc: 95.47% | Val Loss: 0.0513, Val Acc: 98.20%\n",
            "Epoch [5/10] Train Loss: 0.1104, Train Acc: 95.45% | Val Loss: 0.0704, Val Acc: 97.40%\n",
            "Saved best model with val_acc: 98.24%\n",
            "Epoch [6/10] Train Loss: 0.1097, Train Acc: 95.49% | Val Loss: 0.0478, Val Acc: 98.24%\n",
            "Epoch [7/10] Train Loss: 0.1070, Train Acc: 95.65% | Val Loss: 0.0547, Val Acc: 97.80%\n",
            "Epoch [8/10] Train Loss: 0.1072, Train Acc: 95.68% | Val Loss: 0.0506, Val Acc: 98.08%\n",
            "Epoch [9/10] Train Loss: 0.1027, Train Acc: 95.86% | Val Loss: 0.0510, Val Acc: 98.12%\n",
            "Epoch [10/10] Train Loss: 0.0997, Train Acc: 96.08% | Val Loss: 0.0544, Val Acc: 98.08%\n",
            "ResNet18 Test Accuracy: 98.09%\n",
            "\n",
            "==================== Training MobileNetV2 ====================\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 167MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved best model with val_acc: 97.20%\n",
            "Epoch [1/10] Train Loss: 0.1488, Train Acc: 93.92% | Val Loss: 0.0666, Val Acc: 97.20%\n",
            "Saved best model with val_acc: 97.72%\n",
            "Epoch [2/10] Train Loss: 0.1310, Train Acc: 94.69% | Val Loss: 0.0642, Val Acc: 97.72%\n",
            "Epoch [3/10] Train Loss: 0.1267, Train Acc: 94.89% | Val Loss: 0.0700, Val Acc: 97.12%\n",
            "Epoch [4/10] Train Loss: 0.1219, Train Acc: 95.05% | Val Loss: 0.0623, Val Acc: 97.52%\n",
            "Epoch [5/10] Train Loss: 0.1324, Train Acc: 94.76% | Val Loss: 0.0609, Val Acc: 97.68%\n",
            "Epoch [6/10] Train Loss: 0.1293, Train Acc: 94.88% | Val Loss: 0.0689, Val Acc: 97.36%\n",
            "Epoch [7/10] Train Loss: 0.1217, Train Acc: 95.15% | Val Loss: 0.0920, Val Acc: 96.60%\n",
            "Saved best model with val_acc: 97.80%\n",
            "Epoch [8/10] Train Loss: 0.1231, Train Acc: 95.22% | Val Loss: 0.0577, Val Acc: 97.80%\n",
            "Epoch [9/10] Train Loss: 0.1328, Train Acc: 94.77% | Val Loss: 0.0692, Val Acc: 97.00%\n",
            "Epoch [10/10] Train Loss: 0.1252, Train Acc: 95.03% | Val Loss: 0.0618, Val Acc: 97.72%\n",
            "MobileNetV2 Test Accuracy: 97.68%\n",
            "\n",
            "==================== Comparison Results ====================\n",
            "ResNet18 Accuracy: 98.09%\n",
            "MobileNetV2 Accuracy: 97.68%\n",
            "Result: ResNet18 performs better by 0.41%\n"
          ]
        }
      ],
      "source": [
        "# Compare Models\n",
        "resnet_acc = train_and_evaluate('ResNet18')\n",
        "mobile_acc = train_and_evaluate('MobileNetV2')\n",
        "\n",
        "print(f\"\\n{'='*20} Comparison Results {'='*20}\")\n",
        "print(f\"ResNet18 Accuracy: {resnet_acc:.2f}%\")\n",
        "print(f\"MobileNetV2 Accuracy: {mobile_acc:.2f}%\")\n",
        "\n",
        "if resnet_acc > mobile_acc:\n",
        "    print(f\"Result: ResNet18 performs better by {resnet_acc - mobile_acc:.2f}%\")\n",
        "elif mobile_acc > resnet_acc:\n",
        "    print(f\"Result: MobileNetV2 performs better by {mobile_acc - resnet_acc:.2f}%\")\n",
        "else:\n",
        "    print(\"Result: Both models performed equally.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
