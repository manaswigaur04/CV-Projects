{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBhEqJq0WPfn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MkAct4sWUy7"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "    saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "    [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# No augmentation for validation/test\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "    [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhQSZpkvaIDc"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder('data/train', transform=train_transforms)\n",
        "val_dataset = datasets.ImageFolder('data/val', transform=val_transforms)\n",
        "test_dataset = datasets.ImageFolder('data/test', transform=val_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYGJzgeicMvp",
        "outputId": "83129d6b-17d5-47a7-f38e-2bd5234ca875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 20000\n",
            "Validation samples: 2500\n",
            "Test samples: 2459\n"
          ]
        }
      ],
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f'Training samples: {len(train_dataset)}')\n",
        "print(f'Validation samples: {len(val_dataset)}')\n",
        "print(f'Test samples: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjcDtbOZcr1C",
        "outputId": "1a36cc1f-37ca-4bd8-c434-de9f765535b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 109MB/s]\n"
          ]
        }
      ],
      "source": [
        " # Load pretrained ResNet18\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPzRGJFVcx0O"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYJ5eV6Pcze5"
      },
      "outputs": [],
      "source": [
        "# Replace final layer for binary classification\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1-z8puSc02o",
        "outputId": "25deeabb-4ada-4221-c522-8e8d5cd4744c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Training only final layer with 512 output to 2\n"
          ]
        }
      ],
      "source": [
        "# Move to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "print(f'Using device: {device}')\n",
        "print(f'Training only final layer with {model.fc.in_features} output to 2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTCNEeYqc3WB"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hECxFaXMc7y6"
      },
      "outputs": [],
      "source": [
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE6K2BzLc9eY"
      },
      "outputs": [],
      "source": [
        "# Training tracking\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M8ktFVvc_E-",
        "outputId": "fdc265f1-188e-4ac8-9d16-bcb5b2f3435a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved best model with val_acc: 97.80%\n",
            "Epoch [1/10]\n",
            " Train Loss: 0.1590, Train Acc: 93.71%\n",
            " Val Loss: 0.0601, Val Acc: 97.80%\n",
            "\n",
            "Saved best model with val_acc: 98.00%\n",
            "Epoch [2/10]\n",
            " Train Loss: 0.1162, Train Acc: 95.24%\n",
            " Val Loss: 0.0543, Val Acc: 98.00%\n",
            "\n",
            "Saved best model with val_acc: 98.08%\n",
            "Epoch [3/10]\n",
            " Train Loss: 0.1170, Train Acc: 95.25%\n",
            " Val Loss: 0.0518, Val Acc: 98.08%\n",
            "\n",
            "Epoch [4/10]\n",
            " Train Loss: 0.1090, Train Acc: 95.47%\n",
            " Val Loss: 0.0519, Val Acc: 98.08%\n",
            "\n",
            "Epoch [5/10]\n",
            " Train Loss: 0.1118, Train Acc: 95.44%\n",
            " Val Loss: 0.0508, Val Acc: 98.00%\n",
            "\n",
            "Saved best model with val_acc: 98.40%\n",
            "Epoch [6/10]\n",
            " Train Loss: 0.1067, Train Acc: 95.59%\n",
            " Val Loss: 0.0445, Val Acc: 98.40%\n",
            "\n",
            "Epoch [7/10]\n",
            " Train Loss: 0.1102, Train Acc: 95.70%\n",
            " Val Loss: 0.0429, Val Acc: 98.32%\n",
            "\n",
            "Epoch [8/10]\n",
            " Train Loss: 0.1089, Train Acc: 95.64%\n",
            " Val Loss: 0.0586, Val Acc: 98.00%\n",
            "\n",
            "Epoch [9/10]\n",
            " Train Loss: 0.1087, Train Acc: 95.53%\n",
            " Val Loss: 0.0472, Val Acc: 98.16%\n",
            "\n",
            "Saved best model with val_acc: 98.72%\n",
            "Epoch [10/10]\n",
            " Train Loss: 0.1093, Train Acc: 95.45%\n",
            " Val Loss: 0.0393, Val Acc: 98.72%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(val_loader)\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f'Saved best model with val_acc: {val_acc:.2f}%')\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "    print(f' Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f' Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
